{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "## Cutomized modules\n",
    "from ContentParser import ContentParser\n",
    "content_parser = ContentParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashtags Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_to_train =  [\"04-13\", \"04-22\", \"04-30\", \"05-08\", \"05-16\", \"05-25\", \"06-02\", \"06-10\", \"06-14\", \"06-22\"]\n",
    "path_of_data = \"../Retweets/\"\n",
    "whether_save = True\n",
    "save_path = \"../Hashtags_Covariates/\"\n",
    "\n",
    "## Load data\n",
    "retweets_dict = content_parser.read_retweets_for_dates(path_of_data, dates_to_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tweets_hashtags are hashtags for each tweet\n",
    "tweets_hashtags = content_parser.extract_hashtags_for_tweets(retweets_dict)\n",
    "## hashtags_dic is a dictionary of hashtags and their frequencies\n",
    "hashtags_dic = content_parser.generate_hashtags_set(retweets_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "878"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Sort hashtags by their frequencies and only select hashtags with frequencies more than 60\n",
    "sorted_hashtags = sorted(hashtags_dic.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_hashtags_more_than_60 = [hashtag for hashtag in sorted_hashtags if hashtag[1] > 60]\n",
    "hashtags_list = [hashtag[0] for hashtag in sorted_hashtags_more_than_60]\n",
    "len(sorted_hashtags_more_than_60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(878, 159822)\n"
     ]
    }
   ],
   "source": [
    "## Generate matrix for whole sorted hashtags more than 60 where each row is a hashtag and each column is a tweet\n",
    "matrix = content_parser.generate_matrix(tweets_hashtags, hashtags_list)\n",
    "print(matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train the clustering model\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "Z = linkage(matrix, method='complete', metric='yule')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set the distance and generate clusters\n",
    "distance_threshold = 1\n",
    "results = fcluster(Z, t=distance_threshold, criterion='distance')\n",
    "groups = content_parser.generate_topics_clusters(results, hashtags_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## groups example\n",
    "groups['group1']\n",
    "if not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)\n",
    "## Save a goups clustering result of hashtags\n",
    "with open(f'{save_path}groups_clustering.json', 'w') as f:\n",
    "    json.dump(groups, f)\n",
    "    f.close()\n",
    "## Save a full list of hashtags\n",
    "with open(f'{save_path}hashtags_list.json', 'w') as f:\n",
    "    json.dump(hashtags_list, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dates_to_include = [\"04-22\", \"04-26\",\"05-08\", \"05-12\", \"05-16\", \"05-21\", \"05-25\", \"05-29\",\"06-02\", \"06-06\", \"06-10\", \"06-14\", \"06-18\", \"06-22\"]\n",
    "dates_to_include =  [\"04-30\"]\n",
    "path_of_data = \"../Retweets/\"\n",
    "whether_save = True\n",
    "save_path = \"../Hashtags_Covariates/\"\n",
    "\n",
    "## Load Generated groups hashtags\n",
    "with open(f'{save_path}groups_clustering.json', \"r\") as f:\n",
    "    groups = json.load(f)\n",
    "    f.close()\n",
    "with open(f'{save_path}hashtags_list.json', \"r\") as f:\n",
    "    hashtags_list = json.load(f)\n",
    "    f.close()\n",
    "## Load data\n",
    "retweets_dict = content_parser.read_retweets_for_dates(path_of_data, dates_to_include)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate Benchmark Vector\n",
    "benchmark = content_parser.generate_vector_groups(groups, hashtags_list)\n",
    "## Loop through data\n",
    "for date in dates_to_include:\n",
    "    dic_of_users = content_parser.extract_hashtags_for_tweets_and_users(retweets_dict[date])\n",
    "    result = content_parser.generate_users_results(dic_of_users, hashtags_list, benchmark)\n",
    "    result_matrix = content_parser.generate_matrix_for_users_and_groups(result, list(benchmark.keys()))\n",
    "    result_df = pd.DataFrame(result_matrix, index=result.keys(), columns=list(benchmark.keys()))\n",
    "    result_df = result_df.reset_index()\n",
    "    result_df = result_df.rename(columns={'index':'user'})\n",
    "    if whether_save:\n",
    "        result_df.to_csv(f'{save_path}{date}_hashtags_covariates.csv', index=False)\n",
    "    logging.info(f'{date} hashtags preprocessing is done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
